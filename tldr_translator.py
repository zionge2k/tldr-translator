#!/usr/bin/env python3
"""
TLDR Newsletter Translator
Gmail(IMAP)ì—ì„œ TLDR ë‰´ìŠ¤ë ˆí„°ë¥¼ ê°€ì ¸ì™€ì„œ DeepLë¡œ ë²ˆì—­ í›„ Slackìœ¼ë¡œ ë°œì†¡
GitHub Actionsì—ì„œ ì‹¤í–‰ ê°€ëŠ¥
"""

import imaplib
import email
from email.header import decode_header
import json
import os
import re
import requests
from datetime import datetime, timedelta
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸° (GitHub Actions í˜¸í™˜)
GMAIL_ADDRESS = os.environ.get("GMAIL_ADDRESS", "")
GMAIL_APP_PASSWORD = os.environ.get("GMAIL_APP_PASSWORD", "")
DEEPL_API_KEY = os.environ.get("DEEPL_API_KEY", "")
SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL", "")
DEEPL_API_URL = "https://api-free.deepl.com/v2/translate"

# ì²˜ë¦¬ëœ ID íŒŒì¼ ê²½ë¡œ
PROCESSED_IDS_PATH = Path(__file__).parent / "processed_ids.json"

# TLDR ì¢…ë¥˜ë³„ ì´ëª¨ì§€
TLDR_TYPE_EMOJI = {
    "TLDR": "ğŸ“¬",
    "TLDR AI": "ğŸ¤–",
    "TLDR InfoSec": "ğŸ”",
    "TLDR Crypto": "â‚¿",
    "TLDR Founders": "ğŸš€",
    "TLDR Design": "ğŸ¨",
    "TLDR Marketing": "ğŸ“ˆ",
    "TLDR DevOps": "âš™ï¸",
    "TLDR Web": "ğŸŒ",
}


def get_processed_ids():
    if PROCESSED_IDS_PATH.exists():
        with open(PROCESSED_IDS_PATH) as f:
            return set(json.load(f))
    return set()


def save_processed_ids(ids):
    with open(PROCESSED_IDS_PATH, "w") as f:
        json.dump(list(ids), f)


def connect_gmail():
    """Gmail IMAP ì—°ê²°"""
    mail = imaplib.IMAP4_SSL("imap.gmail.com")
    mail.login(GMAIL_ADDRESS, GMAIL_APP_PASSWORD)
    return mail


def search_tldr_emails(mail, days_back=1):
    """TLDR ë‰´ìŠ¤ë ˆí„° ê²€ìƒ‰"""
    mail.select("inbox")

    # ë‚ ì§œ ê¸°ì¤€ ê²€ìƒ‰
    since_date = (datetime.now() - timedelta(days=days_back)).strftime("%d-%b-%Y")
    search_query = f'(FROM "tldrnewsletter.com" SINCE {since_date})'

    status, messages = mail.search(None, search_query)

    if status != "OK":
        return []

    return messages[0].split()


def decode_mime_header(header):
    """MIME í—¤ë” ë””ì½”ë”©"""
    if not header:
        return ""

    decoded_parts = decode_header(header)
    result = []
    for part, encoding in decoded_parts:
        if isinstance(part, bytes):
            result.append(part.decode(encoding or "utf-8", errors="ignore"))
        else:
            result.append(part)
    return "".join(result)


def get_email_content(mail, msg_id):
    """ì´ë©”ì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
    status, msg_data = mail.fetch(msg_id, "(RFC822)")

    if status != "OK":
        return None

    raw_email = msg_data[0][1]
    msg = email.message_from_bytes(raw_email)

    # í—¤ë” ì¶”ì¶œ
    subject = decode_mime_header(msg.get("Subject", ""))
    from_header = decode_mime_header(msg.get("From", ""))
    message_id = msg.get("Message-ID", msg_id.decode())

    # TLDR ì¢…ë¥˜ ì¶”ì¶œ
    tldr_type = "TLDR"
    if match := re.search(r"TLDR\s*(\w+)", from_header):
        tldr_type = f"TLDR {match.group(1)}"

    # ë³¸ë¬¸ ì¶”ì¶œ
    body = ""
    if msg.is_multipart():
        for part in msg.walk():
            if part.get_content_type() == "text/plain":
                payload = part.get_payload(decode=True)
                if payload:
                    charset = part.get_content_charset() or "utf-8"
                    body = payload.decode(charset, errors="ignore")
                    break
    else:
        payload = msg.get_payload(decode=True)
        if payload:
            charset = msg.get_content_charset() or "utf-8"
            body = payload.decode(charset, errors="ignore")

    return {
        "id": message_id,
        "subject": subject,
        "tldr_type": tldr_type,
        "body": body
    }


def extract_links(body):
    """ì´ë©”ì¼ ëì˜ Links ì„¹ì…˜ì—ì„œ URL ì¶”ì¶œ"""
    links = {}
    links_match = re.search(r"Links:\s*-+\s*(.*)", body, re.DOTALL)
    if links_match:
        links_section = links_match.group(1)
        for match in re.finditer(r"\[(\d+)\]\s*(https?://[^\s]+)", links_section):
            links[match.group(1)] = match.group(2)
    return links


def parse_articles(body, links):
    """ê¸°ì‚¬ íŒŒì‹± - ì œëª©, ë§í¬, ìš”ì•½ ì¶”ì¶œ"""
    articles = []
    current_section = ""

    lines = body.split("\n")
    i = 0

    section_emoji = {
        "HEADLINES": "ğŸ“°", "LAUNCHES": "ğŸš€",
        "DEEP DIVES": "ğŸ§ ", "ANALYSIS": "ğŸ”",
        "ENGINEERING": "ğŸ§‘â€ğŸ’»", "RESEARCH": "ğŸ”¬",
        "MISCELLANEOUS": "ğŸ", "QUICK LINKS": "âš¡",
        "BIG TECH": "ğŸ¢", "STARTUPS": "ğŸŒ±",
        "SCIENCE": "ğŸ”­", "PROGRAMMING": "ğŸ’»",
        "SECURITY": "ğŸ”’", "OPINIONS": "ğŸ’­",
    }

    while i < len(lines):
        line = lines[i].strip()

        if not line:
            i += 1
            continue

        # ì„¹ì…˜ í—¤ë” ê°ì§€
        if re.match(r"^[ğŸš€ğŸ§ ğŸ§‘â€ğŸ’»ğŸâš¡ğŸ“°ğŸ”’ğŸ¨ğŸ’°ğŸ“£ğŸ‘”ğŸ”­ğŸ’»ğŸ¢ğŸŒ±ğŸ’­]\s*$", line):
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                if next_line and re.match(r"^[A-Z][A-Z\s&]+$", next_line):
                    current_section = next_line.title()
                    for key, emoji in section_emoji.items():
                        if key in next_line.upper():
                            current_section = f"{emoji} {next_line.title()}"
                            break
                    i += 2
                    continue
            i += 1
            continue

        # ê¸°ì‚¬ ì œëª© íŒ¨í„´
        title_match = re.match(
            r"^(.+?)\s*\((\d+)\s*MINUTE\s*READ\)\s*\[(\d+)\]",
            line,
            re.IGNORECASE
        )

        if title_match:
            title = title_match.group(1).strip()
            link_num = title_match.group(3)
            url = links.get(link_num, "")

            description_lines = []
            i += 1
            empty_line_count = 0

            while i < len(lines):
                desc_line = lines[i].strip()

                if not desc_line:
                    empty_line_count += 1
                    if empty_line_count >= 2:
                        break
                    i += 1
                    continue

                empty_line_count = 0

                if re.match(r"^.+\(\d+\s*MINUTE\s*READ\)\s*\[\d+\]", desc_line, re.IGNORECASE):
                    break
                if re.match(r"^[ğŸš€ğŸ§ ğŸ§‘â€ğŸ’»ğŸâš¡ğŸ“°ğŸ”’ğŸ¨ğŸ’°ğŸ“£ğŸ‘”ğŸ”­ğŸ’»ğŸ¢ğŸŒ±ğŸ’­]\s*$", desc_line):
                    break
                if any(skip in desc_line.lower() for skip in [
                    "sign up", "advertise", "unsubscribe", "manage your",
                    "referral", "tldr is hiring", "want to work", "love tldr"
                ]):
                    break

                description_lines.append(desc_line)
                i += 1

            description = " ".join(description_lines)
            summary = get_summary(description)

            if title and url:
                articles.append({
                    "section": current_section,
                    "title": title,
                    "url": url,
                    "summary": summary
                })
            continue

        i += 1

    return articles


def get_summary(text):
    """ì²« 2ë¬¸ì¥ ì¶”ì¶œ"""
    if not text:
        return ""
    sentences = re.split(r"(?<=[.!?])\s+", text)
    summary = " ".join(sentences[:2])
    if len(summary) > 300:
        summary = summary[:297] + "..."
    return summary


def translate_text(text, target_lang="KO"):
    """DeepL APIë¡œ í…ìŠ¤íŠ¸ ë²ˆì—­"""
    if not text:
        return ""

    response = requests.post(
        DEEPL_API_URL,
        data={
            "auth_key": DEEPL_API_KEY,
            "text": text,
            "target_lang": target_lang
        }
    )

    if response.status_code == 200:
        result = response.json()
        return result["translations"][0]["text"]
    else:
        print(f"DeepL API ì˜¤ë¥˜: {response.status_code}")
        return text


def translate_articles(articles):
    """ê¸°ì‚¬ ë²ˆì—­ (ì œëª© + ìš”ì•½) - ê°œë³„ ë²ˆì—­"""
    if not articles:
        return []

    result = []
    for article in articles:
        translated_title = translate_text(article["title"])
        translated_summary = translate_text(article["summary"])

        result.append({
            "section": article["section"],
            "title": translated_title.strip(),
            "url": article["url"],
            "summary": translated_summary.strip()
        })

    return result


def format_slack_message(email_data, translated_articles):
    """Slack ë©”ì‹œì§€ í¬ë§·"""
    tldr_type = email_data["tldr_type"]
    emoji = TLDR_TYPE_EMOJI.get(tldr_type, "ğŸ“¬")

    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"{emoji} {tldr_type}",
                "emoji": True
            }
        },
        {
            "type": "context",
            "elements": [{
                "type": "mrkdwn",
                "text": f"ğŸ“… {datetime.now().strftime('%Y-%m-%d')} â€¢ {len(translated_articles)}ê°œ ë‰´ìŠ¤"
            }]
        },
        {"type": "divider"}
    ]

    current_section = ""

    for article in translated_articles[:12]:
        if article["section"] and article["section"] != current_section:
            current_section = article["section"]
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*{current_section}*"
                }
            })

        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"<{article['url']}|{article['title']}>\nâ†’ {article['summary']}"
            }
        })

    return {"blocks": blocks}


def send_to_slack(message):
    response = requests.post(
        SLACK_WEBHOOK_URL,
        json=message,
        headers={"Content-Type": "application/json"}
    )
    return response.status_code == 200


def main():
    print(f"[{datetime.now()}] TLDR ë²ˆì—­ê¸° ì‹œì‘")

    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not all([GMAIL_ADDRESS, GMAIL_APP_PASSWORD, DEEPL_API_KEY, SLACK_WEBHOOK_URL]):
        print("ì˜¤ë¥˜: í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        print(f"  GMAIL_ADDRESS: {'âœ“' if GMAIL_ADDRESS else 'âœ—'}")
        print(f"  GMAIL_APP_PASSWORD: {'âœ“' if GMAIL_APP_PASSWORD else 'âœ—'}")
        print(f"  DEEPL_API_KEY: {'âœ“' if DEEPL_API_KEY else 'âœ—'}")
        print(f"  SLACK_WEBHOOK_URL: {'âœ“' if SLACK_WEBHOOK_URL else 'âœ—'}")
        return

    # Gmail ì—°ê²°
    mail = connect_gmail()
    processed_ids = get_processed_ids()

    # TLDR ì´ë©”ì¼ ê²€ìƒ‰
    msg_ids = search_tldr_emails(mail, days_back=1)
    print(f"ë°œê²¬ëœ ì´ë©”ì¼: {len(msg_ids)}ê°œ")

    new_count = 0
    for msg_id in msg_ids:
        email_data = get_email_content(mail, msg_id)

        if not email_data:
            continue

        if email_data["id"] in processed_ids:
            continue

        print(f"\nì²˜ë¦¬ ì¤‘: {email_data['tldr_type']} - {email_data['subject']}")

        links = extract_links(email_data["body"])
        articles = parse_articles(email_data["body"], links)
        print(f"  ê¸°ì‚¬ ìˆ˜: {len(articles)}ê°œ")

        if not articles:
            print("  ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í•¨")
            continue

        translated = translate_articles(articles)
        message = format_slack_message(email_data, translated)

        if send_to_slack(message):
            print(f"  Slack ë°œì†¡ ì„±ê³µ!")
            processed_ids.add(email_data["id"])
            new_count += 1
        else:
            print(f"  Slack ë°œì†¡ ì‹¤íŒ¨")

    mail.logout()
    save_processed_ids(processed_ids)
    print(f"\n[{datetime.now()}] ì™„ë£Œ - {new_count}ê°œ ë°œì†¡")


if __name__ == "__main__":
    main()
